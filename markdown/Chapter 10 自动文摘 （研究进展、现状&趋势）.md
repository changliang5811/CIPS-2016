# Chapter 10 自动文摘
（研究进展、现状&趋势）

## 自动文摘可以做什么？

### 目前挑战：如何将用户从长篇累牍的文字阅读中解放出来是大数据时代面临的一个挑战

### 自动文摘（又称自动文档摘要）是指通过自动分析给定的一篇文档或多篇文档，提炼、总结其中的要点信息，最终输出一篇长度较短、可读性良好的摘要（通常包含几句话或数百字），该摘要中的句子可直接出自原文，也可重新撰写所得。

### 目的：通过对原文本进行压缩、提炼，为用户提供简明扼要的文字描述。用户可以通过阅读简短的摘要而知晓原文中所表达的主要内容，从而大幅节省阅读时间。

### 研究的最终目标：建立有效的自动文摘方法与模型，实现高性能的自动文摘系统。

## 研究内容

### 自动文摘可看作是一个信息压缩过程，将输入的一篇或多篇文档压缩为一篇简短的摘要，涉及到对输入文档的理解、要点的筛选，以及文摘合成这三个主要步骤。

### 要点筛选

- 文档中的重要信息可以通过要点来体现，如何从冗杂的文本信息中筛选出要点，是自动文摘系统能否成功的先决条件。
- 如何表达要点信息？目前各类文摘系统中采用了不同粒度的信息单元来表示要点信息，例如词汇、短语、依存关系、句子、甚至语义图等（没有绝对的优劣之分）。
- 如何评估信息单元的重要性？输入文档中通常包含大量的信息单元，无论是词汇、短语还是句子。从大量信息单元中发现最重要的若干个，为后续文摘合成提供输入。

### 文摘合成

- 根据要点筛选的结果进行摘要的合成，产生最终的摘要。文摘合成步骤需要保证摘要具有良好的要点覆盖性与可读性，且满足摘要长度的限制。
- 采用抽取式还是生成式方法？

	- 抽取式方法基于原文中已有的句子进行文摘合成，利用不同方法对文档结构单元（句子、段落等）进行评价，对每个结构单元赋予一定权重，然后选择最重要的结构单元组成摘要。所产生的摘要语句通顺，目前（2016年）大多数自动文摘系统所采用的方法
	- 生成式方法则利用自然语言理解技术对文本进行语法、语义分析，对信息进行融合，利用自然语言生成技术生成新的摘要句子。直接生成摘要语句，能够得到更加凝练的语句，但语句通顺性不能得到保障。
	- 有一些方法允许对原文语句进行一定的压缩或融合，可以看作是一种混合方法。

- 如何评估摘要的可读性？

	- 摘要可读性是衡量摘要质量的一个重要性质，能够严重影响读者对摘要的主观感受
	- 摘要的可读性不仅依赖于每个句子的通顺性，还依赖于多个句子之间的连贯性

- 如何同时满足摘要的多种性质要求？

	- 早期的自动文摘系统采用贪心的处理方式，分步骤逐一考虑摘要的不同性质
	- 最新的自动文摘系统则力图在统一的优化框架下同时考虑多种性质，从而获得更优的摘要结果。

## 自动文摘

### 自动文摘所采用的方法从实现上考虑可以分为抽取式摘要（extractive summarization）和生成式摘要（abstractive summarization）。（见研究内容之文摘合成部分）

### 技术框架

- 内容表示 → 权重计算 → 内容选择 → 内容组织
- 首先将原始文本表示为便于后续处理的表达方式，然后由模型对不同的句法或语义单元进行重要性计算，再根据重要性权重选取一部分单元，经过内容上的组织形成最后的摘要。
- 内容表示与权重计算

	- 原文档中的每个句子由多个词汇或单元构成，后续处理过程中也以词汇等元素为基本单位，对所在句子给出综合评价分数。
	- 方法一：由于词汇在文档中的出现频次可以在一定程度上反映其重要性，可以使用每个句子中出现某词的概率作为该词的得分，通过将所有包含词的概率求和得到句子得分，或者利用扩展性较强的贝叶斯话题模型，对词汇本身的话题相关性概率进行建模。
	- 方法二：将每个句子表示为向量，维数为总词表大小。通常使用加权频数作为句子向量相应维上的取值，如IF-IDF。或者得到向量表示后计算两两之间的某种相似度（例如余弦相似度），随后根据计算出的相似度构建带权图，图中每个节点对应每个句子。最后以用相似度作为节点之间的边权，通过迭代求解基于图的排序算法来得到句子的重要性得分。
	- 方法三：捕捉每个句子中所描述的概念，例如句子中所包含的命名实体或动词，比如将二元词（bigram）作为概念，也有利用频繁图挖掘算法从文档集中挖掘得到深层依存子结构作为语义表示单元。
	- 方法四：利用公开数据集训练有监督打分模型。对于抽取式摘要，可以人工撰写摘要，然后有监督训练。也有利用隐马尔科夫模型（HMM）、条件随机场（CRF）、结构化支持向量（Structural SVM）等常见序列标注或一般结构预测模型进行抽取式摘要有监督训练的工作。

- 内容选择

	- 因为长度限制，考虑如何在尽可能短的长度里容纳尽可能多的重要信息，在此基础上对原文内容进行选取。
	- 方法一:贪心选择

		- 根据句子或其他单元的重要性得分进行贪心选择。选择过程中需要考虑各单元之间的相似性，尽量避免在最终的摘要中包含重复的信息。
		- 去除冗余机制

			- 法1:最大边缘相关法：在每次选取过程中，贪心选择与查询最相关或内容最重要、同时和已选择信息重叠性最小的结果（类似于TF-IDF）
			- 法2:直接将内容选择的重要性和多样性同时考虑在同一个概率模型框架内，基于贪心选择近似优化似然函数

		- 包括最大边缘相关法在内的很多贪心选择目标函数都具有次模性

			- 这个性质被称为回报递减效应（diminishing returns）
			- 由于每步选择的即时最优性，每次多选入一句话，信息的增加不会比上一步更多（也就是每次所增加的内容一次比一次少）

		- 贪心法易于实现、运行效率高，基于次模函数优化的内容选择在近年得到了很多扩展。

	- 方法二：全局优化

		- 同样以最大化摘要覆盖信息、最小化冗余等要素作为目标，同时可以在优化问题中考虑多种由任务和方法本身的性质所导出的约束条件
		- 最为常用的形式化框架是基于 0-1 二值变量的整数线性规划。最后求解优化问题得到的结果中如果某变量取值为 1，则表示应当将该变量对应的单元选入最后的摘要中。

			- 缺点：为 NP-难问题，此类方法的求解过程在实际应用中会表现较慢，并不适合实时性较高的应用场景

		- 其余方法：DP、最小割问题、对偶分解技术
		- 展望：更为通用的全局优化加速方案目前仍是一个开放问题。

- 内容组织

	- 内容简化与整合

		- 基于句子抽取得到的语句在表达上不够精练，需要通过语句压缩、简化、改写等技术克服这一问题。
		- 现行主要做法基于句法规则或篇章规则
		- 关于语句简化与改写方面目前也有相对独立的研究，主要利用机器翻译模型进行语句串或句法树的转写
		- 生成式摘要：基于句法分析和对齐技术，可以从合并后的词图直接产生最后的句子，或者以约束形式将合并信息引入优化模型等方式来实现。
		- 目前也有研究者尝试通过对原文档进行语义理解，将原文档表示为深层语义形式（例如深层语义图），然后分析获得摘要的深层语义表示（例如深层语义子图），最后由摘要的深层语义表示生成摘要文本（利用自然语言生成技术从语义表达直接生成而得）

	- 内容排序

		- 对于单文档摘要任务而言，所选取内容在原文档中的表述顺序基本可以反映这些内容之间正确的组织顺序，因此通常直接保持所选取内容在原文中的顺序。
		- 对于多文档摘要任务，选取内容来自不同文档，需要考虑内容之间的衔接性与连贯性（目前还处于研究初期阶段）

- 端到端摘要

	- 基 于 编 码器 - 解码器（encoder-decoder）架构的序列到序列学习模型（sequence-to-sequence learning）目前最为流行，因为可以避免繁琐的人工特征提取，也避开了重要性评估、内容选择等技术点的模块化，只需要足够的输入输出即可开始训练。
	- 尝试对语句层次进行编码并在此基础上引入注意机制

## 展望

### 多语言自动文摘资源建设

- 自动文摘资源匮乏，严重影响了这些语言中自动文摘技术的发展。业界需要投入更多的人力物力来建设多语言自动文摘资源，这对自动文摘的研究将起到重大的推动作用

### 自动文摘评价方法的完善

### 基于自然语言生成的自动文摘

- 未来几年将会有越来越多的研究者基于深度学习技术从事生成式摘要方法的研究，也有望取得重要进展。

### 篇章信息和语义信息的有效利用

- 文档本身的语义表达具备很强的结构性，各语义单元之间存在紧密联系，这一点在目前提出的结构预测模型中也几乎没有考虑
- 应尽可能保证最后抽取或生成的摘要在描述上前后一致、表达连贯

### 综述自动生成

### 跨语言自动文摘

- 跨语言自动文摘的目的在于为源语言 A 中的文档以目标语言 B 的形式产生摘要，从而方便了解语言 B 的读者快速了解原文档信息。并不完善的机器翻译性能是跨语言自动文摘的最大障碍，但是随着BERT等模型的出现，情况大为改善

### 多模态摘要

- 文本、图像、视频音频相结合

### 面向复杂问题回答的自动摘要

- 相对完整地回答非事实型问题（为什么，怎么样等）需要对单个文档甚至多个文档中的相关内容进行提取与聚合

