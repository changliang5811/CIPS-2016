# Chapter 14 机器翻译 
 （研究进展、现状&趋势）

## machine translation (MT)

### 利用计算机实现从一种自然语言到另外一种自然语言的自动翻译。被翻译的语言称为源语言（source language），翻译到的语言称作目标语言（target language）。

### 目标：建立有效的自动翻译方法、模型和系统，打破语言壁垒，最终实现任意时间、任意地点和任意语言的自动翻译，完成人们无障碍自由交流的梦想。

### 几乎自然语言处理中的所有问题都会在机器翻译中出现，包括：词法分析（或称形态分析）与词语切分、命名实体识别、句法分析、词义消歧与句子语义表示、自然语言句子生成等，当然在其中最重要的是翻译模型构建问题

## MT基本步骤

### Step 1: 源语言语句的理解

- 包括词语、短语、句子和语篇（对话）等多层次语言单位的处理
- 词语层面：如何界定和切分适合机器翻译的基本语言单元（如汉语、日语、越南语、泰国语等语言的分词问题）、多义词的歧义消解问题以及指代、省略等语言现象的歧义消除等问题
- 短语和句子层面：需要解析句子中词与词之间、短语与短语之间的语义关系。语义理解得越深刻，越有利于机器翻译过程。
- 语篇层面：需要分析句子之间的结构和语义关系，如句子之间的连贯性、衔接性等

### Step 2: 源语言到目标语言的转换

- 核心问题：转换规则（有时候我们称其为“翻译知识”）的表示和获取
- 翻译知识表示主要涉及翻译规则表达的知识层次（基于词、短语、句法子树、语义结构树等）和表示形式（基于离散符号和基于连续实数空间表示方法）
- 翻译知识的获取：一种是基于理性主义思路的专家经验总结和手工编写方式；另一种是基于经验主义思想的以数据驱动的自动获取方法。将翻译知识隐含在神经网络结构和参数中的方法实际上也是一种经验主义方法。

### Step 3: 目标语言生成

- 译文片段的组合方式和目标语言句子的流畅性是目前译文生成中重点关注的两个问题
- 根据翻译系统所接受的输入类型和系统工作方式的不同，机器翻译又可分为文本机器翻译（text-to-text machine translation）、口语翻译（spoken language translation, SLT）和计算机辅助翻译（computer assisted machine translation）。默认情况下，一般指文本机器翻译或者泛指。

## 翻译方法

### 早期：理性主义方法

- 指以语言学理论为基础，由语言学家手工编写翻译规则和词典
- 代表：基于规则的翻译（rule-based machine translation）方法

	- 所有规则几乎都是由通晓双语的语言学专家总结、编纂获得的
	- 这种方法能够充分利用语言学家总结出来的语言规律，具有一定的通用性，因此，对于符合源语言语法规范的句子一旦翻译正确，往往能够获得较高质量的译文
	- 缺点：一般只能处理规范的语言现象，获取规则的人工成本较高，而且维护大规模的规则库往往比较困难，新规则与已有规则易发兼容性问题等

### 经验主义方法

- 以信息论和数理统计为理论基础，以大规模语料库为驱动，通过机器学习技术自动获取翻译知识，这种方法又被称为基于语料库的翻译方法（corpus-based machine translation），或者数据驱动的翻译方法（data-driven machine translation）。
- 主张从已知的翻译实例中自动学习两种语言之间的转换规则
- 早期：基于实例的翻译方法（example-based machine translation）

	- 在事先构建的翻译实例库中找出与待翻译的源语言句子相似的实例（通常是句子），并根据待翻译句子的具体情况对实例对应的译文进行适当的替换、删除和插入等操作，实现翻译过程。
	- 无需对源语言句子进行复杂的分析，可充分利用已经确认的翻译实例，实例一般是句子。
	- 缺点：如何从大规模实例库中快速找到相似度很高的实例，尤其是语义高度相似的实例，始终是该方法面临的挑战

- 中期：统计翻译方法（statistical machine translation）

	- 基本思想是利用机器学习技术从大规模双语平行语料中自动获取翻译规则和概率参数，然后利用翻译规则对源语言句子进行解码。
	- 在统计翻译方法中有三个关键技术模块：语言模型（language model）、翻译模型（translation model）和解码器（decoder）
	- 语言模型用于计算候选译文的句子概率，翻译模型用于计算给定候选译文时源语言句子的概率，解码器用于快速搜索语言模型概率与翻译模型概率相乘之后概率最大的候选译文。为了融入更多的翻译特征，噪声信道模型（IBM，1980-1990）逐渐被对数线性模型所取代。
	- 在 20 多年的发展历程中，统计翻译方法经历了基于词、基于短语和基于句法树翻译模型的一系列转变，如图所示。
	- 基于短语的翻译模型是相对成熟的模型。这里所说的“短语”指连续同现的词串，并非语言学上定义的短语。后续工作主要目的是解决候选译文的消岐问题和目标译文短语的重排序问题。
	- 最近几年，句法翻译模型主要针对其中的两个问题开展研究：（1）句法结构树与词语对齐不兼容；（2）双语的句法知识很难同时被有效地利用。

- 研究热点：基于深度学习的翻译方法（deep-learning based machine translation）

	- 2015年之前，基于DL的MT模型主要以统计翻译为框架，旨在改进源语言句子解析、翻译转换和目标译文生成中的某些关键技术，如词语对齐、翻译概率估计、短语重排序和语言模型等。利用深度学习方法的分布式表示，解决统计翻译方法对全局上下文和深层语义信息建模难的问题
	- 
	- 包含两个神经网络：一个称为编码器（encoder），用于将源语言句子映射为一个（或一组）低维、连续的实数向量；另一个称为解码器（decoder），完成将源语言句子的向量表示转化为目标语言句子。
缺点：无论源语言句子的长短，编码器仅将其映射到一个维数固定的实数向量，很难准确地表示源语言句子的完整语义。
	- Bahdanau 等人将注意机制（attention）思想引入到了端到端的神经网络翻译模型：编码器生成并保留每个源语言词对应的上下文语义向量；解码器每次产生目标语言的单词时，首先利用注意机制模型计算当前译文应与源语言哪些位置的词语有关，然后加权得到源语言的上下文表示，最后用其预测当前译文的概率。

## 展望

### 端到端的神经网络机器翻译的优化

- 增强模型的可解释性、降低神经网络的计算复杂度（使之能在 CPU 上高效训练）、以及设计更加合理的编码和解码网络

### 面向小数据的机器翻译

- 基于深度学习强大的特征表示能力、采用半监督或弱监督的方法解决小数据机器翻译问题

### 非规范文本的机器翻译

- 互联网上使用的语言文本大多具有口语化、社交化等诸多新的特征，弱规范甚至不规范的现象比较严重。提高非规范文本的处理能力和翻译效果

### 篇章级机器翻译

- 现如今的MT模型大多数都是以句子为基本翻译单位进行的，忽略了指代消解、省略和译文句子之间衔接性和连贯性等深层次的语义表达问题。以更大粒度的语言单位（如段落甚至篇章）为翻译单位或上下文背景，对译文的篇章信息进行建模

### 融合离散符号表示与连续向量表示的机器翻译

- 建立于离散符号表示的统计翻译方法与建立于连续向量表示的神经翻译方法都各有其优势，同时各有弊端。设计新的方法融合两者的优势

