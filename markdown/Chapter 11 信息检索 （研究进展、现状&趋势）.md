# Chapter 11 信息检索
（研究进展、现状&趋势）

## 什么是信息检索？

### 信息检索（Information Retrieval, IR）是指将信息按一定的方式加以组织，并通过信息查找满足用户的信息需求的过程和技术。

### 主要任务：协助信息的潜在用户将信息需求转换为一张文献来源列表，而这些文献包含有对其有用的信息（Calvin Mooers, 1951）

### 伴随着互联网及网络信息环境的迅速发展，以网络信息资源为主要组织对象的信息检索系统：搜索引擎应运而生，成为了信息化社会重要的基础设施。

## 研究内容

### 检索用户、信息资源和检索系统三个主要环节组成了信息检索应用环境下知识获取与信息传递的完整结构

### 当前影响信息获取效率的因素也主要体现在这几个环节，即：检索用户的意图表达、信息资源（尤其是网络信息资源）的质量度量、需求与资源的合理匹配。

### 本质上反映了用户个体有限的认知能力与包含近乎无限信息的数据资源空间之间的不匹配问题。

### 关键问题&研究进展

- 信息需求理解

	- 用户与搜索引擎交互过程的核心
	- 面临问题：1.用户可能无法准确表达搜索意图；2. 搜索引擎可能无法正确理解并与恰当的网络资源进行匹配
	- 基于用户行为的分析方法 

		- 用户的信息需求会影响用户提交查询、浏览结果页面、点击相关结果等行为，通过分析用户行为记录，我们将能够有效的检测到一些用户信息需求
		- 1）利用信息需求和点击记录之间的关系——导航类查询倾向于只伴随一次点击，而信息类查询往往伴随多次点击
		- 2）用户提交的查询和提交查询后点击的 URL 会构成一个“查询-点击二部图”。基于该二部图，可以计算一对查询相互之间的相似程度。
		- 3）近年来，眼动追踪技术（Eye tracking）被广泛应用于研究和分析用户与搜索引擎交互过程（如：用户浏览搜索引擎结果页面时的注视位置与用户信息需求相关）
		- 总结：利用包括查询日志、点击日志、眼动信息和鼠标移动信息在内的用户行为信息能够有效的推测查询背后的用户信息需求

	- 基于伪相关反馈信息的分析方法

		- 针对查询频度较低的长尾查询，我们无法获得足够多的用户行为记录，来有效地进行搜索意图分析
		- 尝试基于查询和查询对应的伪相关反馈信息（如搜索引擎结果页的内容），进行搜索意图分析

	- 基于自然语言理解的分析方法 

		- 直接通过对用户输入的检索项进行分析，从而得到用户意图也是近年来的研究热点
		- 针对特定领域检索，提出了结构化表示方法，并利用自然语言处理方法对用户检索项进行语义分析，从而对用户搜索意图进行分析

	- 垂直需求理解分析方法 

		- 现代搜索引擎不再只返回匹配网页，而是根据用户提交的查询，返回包括新闻、图片、视频、本地搜索、购物信息等垂直结果在内的异质化结果页面
		- 关联：垂直搜索资源选择问题。大多数工作将垂直搜索资源选择问题当作一个有监督分类问题处理。

		  利用查询字符串、垂直搜索引擎的查询日志、 垂直搜索引擎、 用户的反馈等信息构建分类模型
		  
- 数据质量评估

	- 资源质量度量：随着互联网信息资源逐渐成为检索系统的主要查找对象，网络资源特有的缺乏编审过程、内容重复度高、质量参差不齐等问题成为了影响检索质量的重要因素。
	- 核心问题：清除索引中的冗余、低质量、不可信和过时数据，而保证真正满足用户需求的数据能够得到检索系统排序算法的关注
	- 基于链接结构的质量评估

		- 主要工作集中在链接关系分析方面，相关工作大都集中在利用PageRank 框架进行某些特定应用需求的改进，或对标准 PageRank 传统算法进行效率提升上。

缺点：搜索引擎对于链接结构数据的依赖也客观上造成了此类数据本身质量堪忧的现象
		- 改进1：采用多种特征共同评价网页质量，设计更加全面合理的质量评估算法（Google Henzinger）
		- 改进2:采用了搜索引擎通过浏览器插件等收集的用户浏览行为数据建立用户浏览关系图替代网络结构图实施链接结构分析（Microsoft）

	- 垃圾网页识别

		- 垃圾网页

			- 利用搜索引擎运行算法的缺陷，采取针对搜索引擎的作弊手段，使其获得高于其网络信息质量排名效果的网页
			- 作弊方式主要可以分为基于内容的作弊（Content Spamming）与基于链接关系的作弊（Link Spamming）两种类型，这是从影响搜索引擎检索结果排序的两个不同角度对作弊手段进行的分类

		- 传统的垃圾网页识别方法，大都是针对特定的作弊手段设计有针对性的识别算法予以应对，如采用内容压缩比、可见内容比例等特征识别关键词堆砌类垃圾网页，采用脚本解析应对自动跳转类垃圾网页等。

缺点：缺乏对新出现垃圾网页的应对能力，缺乏识别通用性
		- 改进1:试图采用链接结构分析方法避免对垃圾网页作弊手段本身的关注，代表性算法包括 TrustRank 及其延伸算法 Anti-TrustRank、 GoodBadRank 等
		- 改进2:为了避免链接结构分析算法本身面临的链接结构数据质量问题，可利用用户与垃圾和正常网页的交互模式差异，从作弊目的而非手段的角度来识别垃圾网页

- 检索结果排序

	- 结果匹配排序：数据对象的多样化、异构化导致高度动态繁杂的泛在网络内容使得文本相似度计算方法无法适用；基于同质性假设构建的用户行为模型难以应对；基于单一维度的结果分布规律的用户行为假设大量失效。迫切需要构建适应现代信息资源环境的检索结果匹配排序方法
	- 检索系统交互方式：依据用户提交的查询，按照内容相似程度、质量水平、用户偏好情况、竞价情况、时效性情况等因素将结果文档进行排序，并以有序列表的形式反馈给用户
	- 1) 信息检索模型

		- 对查询和文档进行表示并进行相似度计算的框架和方法
		- 信息检索排序模型分类图

	- 2)排序学习

		- 实际搜索引擎中需要考虑的排序因素已经成百上千，单靠人工将它们整合到一个排序公式中已经不太现实
		- 使用排序学习方法，即从用户标注或者搜索日志数据中利用机器学习的方法训练排序模型（如图所示）。
		- 与传统排序模型相比，排序学习的优势在于对大量的排序特征进行组合优化，自动进行参数的学习，最终得到一个高效精准的排序模型。
		- 将排序看做回归或者分类问题所提出的单点型排序学习算法（Pointwise 算法）（早期）
		- 点对型排序学习算法（Pairwise 算法），其思想是将排序问题看做是同一查询下两个文档间的相对相关性关系建模（曾占主导地位）
		- 列表型排序学习算法（Listwise 算法），该方式直接建模一系列文档间的序列型关系，避免了前两类方法的近似误差（即优化目标定义在整个序列上）

	- 3)多样化搜索

		- 出现原因：1. 网络数据存在大量的冗余信息；2. 很多用户查询具有歧义；3. 对同一个查询不同的用户有不同方面的信息需求。
		- 目的：进一步考虑结果之间的差异性（或者说结果的新颖性）去除冗余、覆盖不同信息需求。
		- 早期解决办法：启发式的排序模型

			- 隐式的方法主要假设相似的文档覆盖的话题或者满足的信息需求相似，通过定义文档间的依赖关
系来捕捉多样性
			- 显式的方法则是通过显式地定义或者挖掘查询的各个子话题，从而直接选择能够覆盖这些子话题的文档作为排序结果

		- 近年来，越来越多的工作通过机器学习的方法进行结果的多样性排序。为了建模多样性，排序学习模型需要考虑文档间的关系（序列级（listwise）排序方法）

优化目标从极大似然的目标发展为直接优化多样性评价指标
		- 深度学习的方法也被引入到多样性排序工作中来，以便解决传统机器学习方法中多样性特征难以定义的难题

	- 4)个性化搜索

		- 基于内容分析的算法

			- 通过比较用户兴趣爱好和结果文档的内容相似性来对文档的用户相关性进行判断进而对搜索结果进行重排
			- 用户模型一般表述为关键词或主题向量或层次的形式
			- 通过比较用户模型和文档的相似性，判断真实的搜索意图，并估计文档对用户需求的匹配程度

		- 基于链接分析的方法

			- 利用互联网上网页之间的链接关系，并假设用户点击和访问过的网页为用户感兴趣的网页
			- 进行迭代最终计算出用户对每个网页的喜好度

		- 基于协作过滤的算法

			- 借鉴了基于协作过滤的推荐系统的思想
			- 不仅仅利用用户个人的信息，还利用与用户相似的其它用户或群组的信息，并基于用户群组和相似用户的兴趣偏好来个性化当前用户的搜索结果
			- 用户之间的相似性可以通过用户的兴趣爱好、历史查询、点击过的网页等内容计算得出

	- 5)排序点击模型

		- 搜索引擎用户在与搜索引擎的交互过程中反映出的隐性反馈信息(主要是点击行为信息)是搜索引擎用来改进结果排序的重要影响因素
		- 现状：由于结果位置、展现形式等各种因素的影响，将反馈信息直接应用于搜索排序任务往往难以取得较好的效果
		- 构建描述用户点击行为的点击模型(Click Model)，并基于不同的点击模型估计用户对展现结果的浏览概率，进而尝试去除结果展现位置等因素对用户行为的偏置性影响，以达到更好利用隐性反馈信息的目的
		- 传统的点击模型主要针对于传统同质化的搜索页面进行设计

			- 同质化搜索页面：搜索页面中的结果均采用相近的文本形式展现，结果之间除了文字内容不同外并没有明显的展现形式差异
			- 级联模型（Cascade model），依赖点击模型（Dependent Click Model，DCM），用户浏览模型（User Browsing Model，UBM），动态贝叶斯网络模型（Dynamic Bayesian Network，DBN）等
			- 依照结果位置因素提出用户检验行为假设，并进而对点击行为进行推演。

		- Web2.0时代：针对于垂直搜索结果的点击模型以及针对非顺序检验行为的点击模型

			- 契机：富媒体展现形式被越来越多的应用于搜索交互界面，搜索结果也变得越来越异质化
			- 垂直搜索模型：联合点击模型（Federated Click Model，FCM）模型与垂直点击模型（Vertical Click Model，VCM）
			- 多媒体垂直结果对用户的前2 秒视觉注视行为的影响（左侧为不含垂直结果的页面，右侧为包含多媒体垂直结果的页面）

			- 非顺序检验行为的建模方面：时间点击模型（Temporal Click Model，TCM），局部可观测马尔科夫模型（Partially Observable Markov Model，POM）以及基于真实用户眼动行为实验提出的局部有序点击模型（Partially Sequential Click Model，PSCM）

- 检索性能评价

	- 信息检索评价：信息检索和信息获取系统核心的目标是帮助用户获取到满足他们需求的信息，而评价系统的作用是帮助和监督研究开发人员向这一核心目标前进，以逐步开发出更好的系统，进而缩小系统反馈和用户需求之间的差距，提高用户满意度
	- 对搜索系统的评价包括什么？

		- 检索效率（Efficiency）评价主要考虑检索的时间开销、空间开销和响应速度等
		- 检索结果质量（Effectiveness）评价：重点考虑检索结果是否满足用户的信息需求，如考虑返回的文档中有多少相关文档、所有相关文档中返回了多少、返回的是否靠前等，是评测的重点。
		- 用户界面友好度及易用性（Interface）的评价

	- 方法1:离线性能评价

		- 主要采用基于Cranfield 范式的方法：主要特点是使用一套可重用的评测集来评价信息检索系统的好坏
		- 整个Cranfield 评测集通常包括一个文档集合,一个信息需求的集合,以及和信息需求集合匹配的标注集，静态的，可重用的，一旦被构建,就可以被用来评测新的搜索系统
		- 不同的搜索系统通过在相同的文档集合需求集上生成结果并通过统一的标注集进行评测对比来比较彼此之间的优劣
		- 常见评测集：TREC 会议构建的评测集、NTCIR 会议构建的评测集、跨语言检索评测集（CLEF组织）
		- 不同的评测指标通常具有不同的表达能力和适用范围。

	- 方法2:在线性能评价

		- 不需要专业人员进行针对文档相关性的标注，而是依照用户在使用检索系统时的显式（Explicit）或隐式（Implicit）反馈信息对检索系统的性能进行评价。
		- 用户显式反馈信息：满意度评价（Satisifaciton）、用户偏好（Preference）、信息需求完成情况（Search Outcome）等
		- 用户隐式反馈信息：用户点击（Click-through）、查询重组（Query reformulation）、停留时间（Dwell time）等交互行为信息。
		- 利用机器学习方法对各类隐式反馈信息进行综合，并对满意度评价、用户偏好等显式反馈信息进行预测

		  通常使用的隐式反馈信息包括用户与搜索引擎交互过程中的各种粗粒度（Coarse grain，如查询修改、结果点击等）或细粒度（Fine grain，如鼠标滚轮行为，结果页面停留时间、鼠标移动行为模式等）信息。
		  
## 展望

### 交互式搜索技术

- 案例：Apple 公司Siri，微软公司Cortana，谷歌公司Google Now 等在内的深度整合交互式搜索功能的移动互联网新产品都是这一发展趋势的见证
- 目标：实现人类自由交谈、解决人类面临的日常生活中的各类问题
- 挑战：用户理解与建模、搜索资源整合和自然语言交互能力，缺乏对于自然界与人类社会中各类常识性知识的积累与理解

### 搜索意图理解技术

- 现状：搜索引擎的数据对象已经扩展到包括虚拟空间、物理世界、人类社会在内的泛在网络空间中，内容和使用场景都开始多样化，导致用户的搜索意图相应的变得多样化、异质化

### 语义搜索技术

- 现状：传统的搜索引擎越来越难满足用户快速查找信息的需求以及所需的信息
- 以知识图谱为代表的语义搜索（Semantic Search）将语义Web 技术和传统的搜索引擎技术结合，是一个很有研究价值的课题

### 发展重点将有可能集中在以各种情境的垂直搜索资源为基础，知识化推理为检索运行方式，自然语言多媒体交互为手段的智能化搜索与推荐技术

